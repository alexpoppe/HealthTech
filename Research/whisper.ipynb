{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert wav to mp3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "brew install ffmpeg to install ffmpeg before continuing\n",
    "\n",
    "use python 3.7 - 3.10.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='../Data/testfile.mp3'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "AudioSegment.from_wav(\"../Data/testfile.wav\").export(\"../Data/testfile.mp3\", format=\"mp3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whisper AI on mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /private/var/folders/m0/7534pdbd5n16nwc4zl4gmb3h0000gn/T/pip-req-build-4f1oghbz\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /private/var/folders/m0/7534pdbd5n16nwc4zl4gmb3h0000gn/T/pip-req-build-4f1oghbz\n",
      "  Resolved https://github.com/openai/whisper.git to commit b5851c6c40e753606765ac45b85b298e3ae9e00d\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /Users/alexanderpoppe/miniforge3/envs/voice/lib/python3.10/site-packages (from openai-whisper==20230314) (2.0.0)\n",
      "Collecting numba\n",
      "  Downloading numba-0.56.4-cp310-cp310-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/alexanderpoppe/miniforge3/envs/voice/lib/python3.10/site-packages (from openai-whisper==20230314) (1.24.2)\n",
      "Collecting more-itertools\n",
      "  Using cached more_itertools-9.1.0-py3-none-any.whl (54 kB)\n",
      "Collecting ffmpeg-python==0.2.0\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting tiktoken==0.3.1\n",
      "  Downloading tiktoken-0.3.1-cp310-cp310-macosx_11_0_arm64.whl (700 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m701.0/701.0 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting future\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting regex>=2022.1.18\n",
      "  Downloading regex-2023.3.23-cp310-cp310-macosx_11_0_arm64.whl (288 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.9/288.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /Users/alexanderpoppe/miniforge3/envs/voice/lib/python3.10/site-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2.28.2)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.23.5-cp310-cp310-macosx_11_0_arm64.whl (13.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Using cached llvmlite-0.39.1-cp310-cp310-macosx_11_0_arm64.whl (23.1 MB)\n",
      "Requirement already satisfied: setuptools in /Users/alexanderpoppe/miniforge3/envs/voice/lib/python3.10/site-packages (from numba->openai-whisper==20230314) (67.6.1)\n",
      "Requirement already satisfied: jinja2 in /Users/alexanderpoppe/miniforge3/envs/voice/lib/python3.10/site-packages (from torch->openai-whisper==20230314) (3.1.2)\n",
      "Requirement already satisfied: filelock in /Users/alexanderpoppe/miniforge3/envs/voice/lib/python3.10/site-packages (from torch->openai-whisper==20230314) (3.10.7)\n",
      "Requirement already satisfied: networkx in /Users/alexanderpoppe/miniforge3/envs/voice/lib/python3.10/site-packages (from torch->openai-whisper==20230314) (3.1)\n",
      "Requirement already satisfied: sympy in /Users/alexanderpoppe/miniforge3/envs/voice/lib/python3.10/site-packages (from torch->openai-whisper==20230314) (1.11.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/alexanderpoppe/miniforge3/envs/voice/lib/python3.10/site-packages (from torch->openai-whisper==20230314) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alexanderpoppe/miniforge3/envs/voice/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/alexanderpoppe/miniforge3/envs/voice/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/alexanderpoppe/miniforge3/envs/voice/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alexanderpoppe/miniforge3/envs/voice/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/alexanderpoppe/miniforge3/envs/voice/lib/python3.10/site-packages (from jinja2->torch->openai-whisper==20230314) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/alexanderpoppe/miniforge3/envs/voice/lib/python3.10/site-packages (from sympy->torch->openai-whisper==20230314) (1.3.0)\n",
      "Building wheels for collected packages: openai-whisper, future\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=796930 sha256=b0e0b470a784e2d160d916e34467b22211f636ef7eab6455bd3f06cc16fbb926\n",
      "  Stored in directory: /private/var/folders/m0/7534pdbd5n16nwc4zl4gmb3h0000gn/T/pip-ephem-wheel-cache-h73nud5a/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492022 sha256=a1a465e5e8faed4319c11470100c1b06f4f680bcc5ca65b0bede050695cf4171\n",
      "  Stored in directory: /Users/alexanderpoppe/Library/Caches/pip/wheels/5e/a9/47/f118e66afd12240e4662752cc22cefae5d97275623aa8ef57d\n",
      "Successfully built openai-whisper future\n",
      "Installing collected packages: tqdm, regex, numpy, more-itertools, llvmlite, future, tiktoken, numba, ffmpeg-python, openai-whisper\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.2\n",
      "    Uninstalling numpy-1.24.2:\n",
      "      Successfully uninstalled numpy-1.24.2\n",
      "Successfully installed ffmpeg-python-0.2.0 future-0.18.3 llvmlite-0.39.1 more-itertools-9.1.0 numba-0.56.4 numpy-1.23.5 openai-whisper-20230314 regex-2023.3.23 tiktoken-0.3.1 tqdm-4.65.0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import os\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 139M/139M [00:10<00:00, 14.2MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is multilingual and has 71,825,920 parameters.\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"base\", device=DEVICE)\n",
    "print(\n",
    "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
    "    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = whisper.load_audio(\"../Data/testfile.mp3\")\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "mel = whisper.log_mel_spectrogram(audio).to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: en\n"
     ]
    }
   ],
   "source": [
    "_, probs = model.detect_language(mel)\n",
    "print(f\"Detected language: {max(probs, key=probs.get)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, this is a test. We'll take your recording for myself. Then I will see if this can be transformed into text.\n"
     ]
    }
   ],
   "source": [
    "options = whisper.DecodingOptions(language=\"en\", without_timestamps=True, fp16 = False)\n",
    "result = whisper.decode(model, mel, options)\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderpoppe/miniforge3/envs/voice/lib/python3.10/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello, this is a test. We'll take your recording for myself. Then I will see if this can be transformed into text.\n"
     ]
    }
   ],
   "source": [
    "result = model.transcribe(\"../Data/testfile.mp3\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderpoppe/miniforge3/envs/voice/lib/python3.10/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello, this is a test. Well, take a recording for myself. Then I will see if this can be transformed into text.\n"
     ]
    }
   ],
   "source": [
    "result = model.transcribe(\"../Data/testfile.wav\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
